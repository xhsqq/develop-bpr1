# 优化配置：提升收敛速度
model:
  # Architecture
  modality_dims:
    text: 768
    image: 2048
  
  hidden_dim: 512  # ⭐ 增大容量 (原256)
  item_embed_dim: 256  # ⭐ 增大embedding维度 (原128)
  
  # Disentangled dimensions
  disentangled_dim: 128
  num_disentangled_dims: 3
  
  # Quantum-inspired multi-interest
  num_interests: 4
  quantum_state_dim: 64
  use_quantum_computing: false
  
  # Loss weights - 简化版本，专注推荐
  alpha_recon: 0.01  # ⭐ 大幅降低 (原0.1)
  alpha_causal: 0.001  # ⭐ 大幅降低 (原0.5)
  alpha_diversity: 0.001  # ⭐ 大幅降低 (原0.1)
  alpha_orthogonality: 0.001  # ⭐ 大幅降低 (原0.1)

# Training
training:
  batch_size: 256  # ⭐ 增大batch (原64)
  epochs: 50
  learning_rate: 0.003  # ⭐ 增大学习率 (原0.001)
  weight_decay: 0.00001  # ⭐ 降低正则 (原0.0001)
  warmup_steps: 1000
  optimizer: "adamw"
  scheduler: "cosine"
  gradient_clip: 1.0
  early_stopping:
    patience: 10
    min_delta: 0.001
  
  # Regularization
  dropout: 0.1

# Data
data:
  category: "beauty"
  data_dir: "data/processed"
  max_seq_length: 50
  num_workers: 8
  use_text_features: false  # ⭐ 先关闭，简化调试
  filter_train_items: true

# Evaluation
evaluation:
  eval_batch_size: 512
  eval_every: 1
  save_best: true
  metrics:
    - "HR@5"
    - "HR@10"
    - "HR@20"
    - "HR@50"
    - "NDCG@5"
    - "NDCG@10"
    - "NDCG@20"
    - "NDCG@50"
    - "MRR"
  main_metric: "NDCG@10"

# Logging
logging:
  log_dir: "logs"
  tensorboard: true
  wandb: false
  log_every: 50
