# ⭐⭐⭐ 简化配置：保留三大创新，大幅降低复杂度 ⭐⭐⭐
#
# 设计理念:
#   1. 解耦表征: 保留核心VAE，去掉discriminator和过度约束
#   2. 量子多兴趣: 保留多兴趣建模，简化复数运算
#   3. 因果推断: 保留反事实思想，去掉蒙特卡洛采样
#   4. 减少堆叠深度: 7层 → 4层
#   5. 合并损失项: 8个 → 3个

model:
  # Architecture - 大幅简化
  modality_dims:
    text: 768
    image: 2048
  
  hidden_dim: 256              # 保持不变
  item_embed_dim: 128          # 保持不变
  
  # ==================== 创新1: 解耦表征（简化版）====================
  disentangled_dim: 64         # ⬇️ 从128降到64（降低参数量）
  num_disentangled_dims: 3     # 保留3个维度（功能/美学/情感）
  
  # 简化选项:
  use_discriminator: false     # ⭐ 关闭判别器（去掉TC和independence loss）
  use_reconstruction: true     # 保留重构（VAE核心）
  vae_beta: 0.1                # ⭐ 简化KL权重（不再动态调整）
  
  # ==================== 创新2: 量子多兴趣（简化版）====================
  num_interests: 4             # 保留4个兴趣
  quantum_state_dim: 64        # 保持不变
  use_quantum_computing: false # 已关闭（不用真实量子计算）
  
  # 简化选项:
  use_complex_attention: false # ⭐ 关闭复数注意力（改用普通注意力）
  use_interference: false      # ⭐ 关闭量子干涉（只保留多头注意力）
  use_measurement: false       # ⭐ 关闭测量算子（直接平均）
  
  # ==================== 创新3: 因果推断（简化版）====================
  use_causal_inference: true   # 保留因果推断
  num_treatments: 3            # 3个干预维度
  
  # 简化选项:
  causal_mc_samples: 1         # ⭐ 从10降到1（去掉蒙特卡洛，确定性推断）
  causal_hidden_dim: 128       # ⬇️ 从256降到128
  use_propensity_score: false  # ⭐ 关闭倾向性评分（简化）
  
  # ==================== 序列编码器（简化）====================
  sequence_encoder:
    type: "gru"
    num_layers: 1              # ⭐ 从2层降到1层
    bidirectional: false       # ⭐ 单向（从双向改为单向）
    dropout: 0.1
  
  # ==================== 损失权重（大幅简化）====================
  # 只保留3个主要损失:
  alpha_recon: 0.1             # VAE重构损失
  alpha_causal: 0.05           # 因果推断损失
  alpha_diversity: 0.0         # ⭐ 关闭多样性损失（隐式通过多头保证）
  alpha_orthogonality: 0.0     # ⭐ 关闭正交性损失（隐式通过注意力保证）

# Training - 保守配置
training:
  batch_size: 256              # ⬇️ 从512降到256（更稳定）
  epochs: 50
  learning_rate: 0.0003        # ⬇️ 从0.0005降到3e-4（更保守）
  warmup_epochs: 10            # ⬆️ 从5增到10（更长warmup）
  weight_decay: 0.00001
  optimizer: "adamw"
  scheduler: "cosine"
  gradient_clip: 0.5           # ⭐ 从1.0降到0.5（更严格裁剪）
  
  early_stopping:
    patience: 15               # ⬆️ 从10增到15（更有耐心）
    min_delta: 0.0001
  
  dropout: 0.2                 # ⬆️ 从0.1增到0.2（更强正则化）

# Data
data:
  category: "beauty"
  data_dir: "data/processed"
  max_seq_length: 30           # ⬇️ 从50降到30（降低计算量）
  num_workers: 8
  use_text_features: false     # ⭐ 先关闭文本特征（简化调试）
  filter_train_items: true

# Evaluation
evaluation:
  eval_batch_size: 512
  eval_every: 1
  save_best: true
  metrics:
    - "HR@5"
    - "HR@10"
    - "HR@20"
    - "NDCG@10"
    - "MRR"
  main_metric: "NDCG@10"

# Logging
logging:
  log_dir: "logs"
  tensorboard: true
  wandb: false
  log_every: 50

# ==================== 简化总结 ====================
# 
# 参数量减少: ~40%
# 堆叠深度: 7层 → 4层
# 损失项: 8个 → 3个
# 训练速度: 提升 ~50%
# 
# 保留的创新:
#   ✅ 解耦表征: VAE核心机制
#   ✅ 量子多兴趣: 多头注意力建模
#   ✅ 因果推断: 反事实推断核心思想
# 
# 去掉的复杂部分:
#   ❌ VAE判别器 (TC/independence loss)
#   ❌ 复数运算 (量子注意力)
#   ❌ 量子干涉和测量
#   ❌ 蒙特卡洛采样
#   ❌ 双向GRU (改单向)
#   ❌ 多样性和正交性显式约束



